import warnings
warnings.filterwarnings("ignore", "\nPyarrow", DeprecationWarning)
import matplotlib.pyplot as plt
import pandas as pd
import re
import nltk
from nltk.corpus import stopwords
data = pd.read_csv(r"C:\Users\Bhavani prasad\Videos\Captures\B.TECH CSE\Sem 4\INT 254 (FML)\project\IMDB Dataset.csv")
print(data)


def preprocess_text(text):
    # Remove HTML tags
    text = re.sub(r'<[^>]+>', '', text)

    # Remove non-alphanumeric characters
    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)

    # Convert to lowercase
    text = text.lower()

    # Tokenize
    words = text.split()

    # Remove stopwords (you'll need to import stopwords from nltk)
    stopwords = set(nltk.corpus.stopwords.words('english'))
    words = [w for w in words if not w in stopwords]
    # You may choose to apply stemming or lemmatization here
    # Join the words back into a string
    cleaned_text = ' '.join(words)

    return cleaned_text


# Apply preprocessing function to your DataFrame
data['review'] = data['review'].apply(preprocess_text)
print(data)

# checking negative and postive comments
check_review = data['sentiment'].value_counts()
print(check_review)

# draw Wordcloud
# Generate WordCloud for negative reviews
from wordcloud import WordCloud

negative_reviews = ' '.join(data['review'][data['sentiment'] == 'negative'])

if len(negative_reviews) > 0:
    wordcloud = WordCloud(height=400, width=800, max_font_size=100).generate(negative_reviews)
    plt.figure(figsize=(15, 12))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.title('Word Cloud for Negative Reviews')
    plt.show()
else:
    print("No words found in negative reviews after preprocessing.")

# Generate WordCloud for positive reviews
positive_reviews = ' '.join(data['review'][data['sentiment'] == 'positive'])

if len(positive_reviews) > 0:
    wordcloud = WordCloud(height=400, width=800, max_font_size=100).generate(positive_reviews)
    plt.figure(figsize=(15, 12))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.title('Word Cloud for positive Reviews')
    plt.show()
else:
    print("No words found in positive reviews after preprocessing.")

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

# Split data into features (X) and target (y)
X = data['review']
y = data['sentiment']

# Convert sentiment labels to numeric values (0 for negative, 1 for positive)
y = y.map({'negative': 0, 'positive': 1})

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define a TF-IDF Vectorizer
tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed

# Choose models and create pipelines
models = [
    ('Logistic Regression', LogisticRegression()),
    ('Random Forest', RandomForestClassifier(n_estimators=100))
]

# Train and evaluate each model
for name, model in models:
    # Create a pipeline with TF-IDF vectorizer and the current model
    pipeline = Pipeline([('tfidf', tfidf_vectorizer), ('model', model)])

    # Train the model
    pipeline.fit(X_train, y_train)

    # Predict on the test set
    y_pred = pipeline.predict(X_test)

    # Evaluate the model
    accuracy = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred, target_names=['negative', 'positive'])

    # Print the model name and evaluation metrics
    print(f"----- {name} -----")
    print(f"Accuracy: {accuracy:.4f}")
    print("Classification Report:")
    print(report)
    print()
